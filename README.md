# MAI_AI_frameworks_lab

# Итоги и анализ результатов лабораторной работы

## Задача классификации
### Метрика: accuracy
| Алгоритм | Библиотечная реализация (стандартный бейзлайн) | Библиотечная реализация (улучшенный бейзлайн) | Собственная реализация (стандартный бейзлайн) | Собственная реализация (улучшенный бейзлайн) |
| --- | --- | --- | --- | --- |
| KNN | 0.8870 | 0.8847 | 0.8549 | **0.8825** (*) | 
| Logistic regression | 0.8572 | 0.8813 | 0.8274 | 0.7701 | 
| Decision Tree | 0.8286 | 0.8819 | 0.8257 | 0.8807 | 
| RandomForest | **0.8962** (*) | **0.8876**(*) | 0.8268 | 0.8268 | 
| Gradboost | 0.8899 | 0.8715 | **0.8578** (*) | 0.8549 | 

## Задача регрессии
### Метрика: MSE
| Алгоритм | Библиотечная реализация (стандартный бейзлайн) | Библиотечная реализация (улучшенный бейзлайн) | Собственная реализация (стандартный бейзлайн) | Собственная реализация (улучшенный бейзлайн) |
| --- | --- | --- | --- | --- |
| KNN | 713.4466 | 526.7776 | 713.7194 | 526.7776 | 
| Linear regression | 687.1066 | 674.0785 | 1251.2675 | 1269.9549 | 
| Decision Tree | 890.9472 | 604.377 | 961.1001 | 635.0551 | 
| RandomForest | **476.6302** (*) | **433.52** (*) | 677.0049 | 671.4459 | 
| Gradboost | 582.0431 | 504.212 | **584.7498** (*) | **461.6550** (*) | 

## Классификация:
Лучшие результаты в задаче классификации демонстрируют ансамблевые методы, прежде всего RandomForest. Максимальная достигнутая accuracy - у библиотечной реализации RandomForest в стандартном бейзлайне (0.8962). Ограниченный перебор гиперпараметров снизил потенциал некоторых моделей, прежде всего Gradient Boosting и логистической регрессии, которые чувствительны к подбору learning rate, глубины деревьев и регуляризаторов. Библиотечные версии моделей ожидаемо показали более высокую точность: они оптимизированы и используют продвинутые алгоритмические улучшения. Собственные реализации, несмотря на упрощённость, продемонстрировали корректность работы: например, KNN (0.8825) с улучшенным бейзлайном почти сравнялся с библиотечной версией. Наибольшая разница между собственными и библиотечными версиями наблюдается у Logistic Regression и RandomForest. Из-за сокращённого пространства вариантов подбора гиперпараметров (поскольку их подбор занимал слишком много времении и вычислительной мощности) многие модели могли не достигнуть оптимальной точки.

## Регрессия:
В регрессии картина аналогична классификации: лучше всего показывают себя ансамбли - RandomForest и Gradient Boosting. Разрыв в качестве между собственными и библиотечными моделями в регрессии выражен сильнее, чем в классификации. Библиотечные алгоритмы (особенно ансамбли) могли значительно улучшить качество при более широком поиске. Собственные реализации также ограничены по времени, поэтому глубина деревьев, количество итераций бустинга и шаги обучения использовались в компактных диапазонах — что напрямую повлияло на итоговый MSE.


Ансамбли остаются самыми эффективными методами, даже при сокращённом поиске параметров. Ограничение гиперпараметров существенно влияет на качество, особенно для регрессионных моделей и логистической регрессии - это важно учитывать при интерпретации итоговых метрик. Собственные реализации показали корректность, пусть и уступают библиотечным версиям - что естественно с учётом отсутствия оптимизаций. Улучшенный бейзлайн положительно влияет на результат, но степень улучшения сильно зависит от модели.
