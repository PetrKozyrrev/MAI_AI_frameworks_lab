{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb8RvVCh4QxT"
      },
      "source": [
        "# Лабораторная работа №4 (Проведение исследований со случайным лесом)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TFs-y4l-ncCA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from typing import Optional\n",
        "from scipy.stats import randint\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1eGJ2KA4uDg",
        "outputId": "87da18d3-2b31-4b6a-d789-16cf2879056d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3011999291.py:2: DtypeWarning: Columns (9,10,11,14,15,16,17) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_reg = pd.read_csv('regression.csv')\n"
          ]
        }
      ],
      "source": [
        "df_class = pd.read_csv('classification.csv')\n",
        "df_reg = pd.read_csv('regression.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNXbcoZF5EcC"
      },
      "source": [
        "Датасет для классификации (Air Quality & Health Impact Analysis):\n",
        "* **RecordID:** Уникальный идентификатор, присваиваемый каждой записи\n",
        "* **AQI:** Индекс качества воздуха, показывающий, насколько загрязнен воздух в настоящее время или насколько загрязненным он, по прогнозам, станет в будущем\n",
        "* **PM10**:  Концентрация твердых частиц диаметром менее 10 микрометров (μg/m³)\n",
        "* **PM2_5**: Концентрация твердых частиц диаметром менее 2,5 микрометров (μg/m³)\n",
        "* **NO2**: Концентрация диоксида азота (ppb)\n",
        "* **SO2**: Концентрация диоксида серы (ppb)\n",
        "* **O3**: Концентрация озона (ppb)\n",
        "* **Temperature**: Температура в градусах Цельсия (°C)\n",
        "* **Humidity**: Процент влажности (%)\n",
        "* **WindSpeed**: Скорость ветра (m/s)\n",
        "* **RespiratoryCases**: Количество зарегистрированных респираторных случаев.\n",
        "* **CardiovascularCases**: Количество зарегистрированных сердечно-сосудистых случаев\n",
        "* **HospitalAdmissions**: Количество зарегистрированных случаев госпитализации\n",
        "* **Target Variable: HealthImpactClass**\n",
        "\n",
        "Датасет для регрессии (Electrity Prices):\n",
        "* **DateTime**: дата и время\n",
        "* **Holiday**: название праздника, если день нерабочий день\n",
        "* **HolidayFlag**: целое число, 1, если день нерабочий день, ноль в противном случае\n",
        "* **DayOfWeek**: целое число (0-6), 0 понедельник, день недели\n",
        "* **WeekOfYear**: текущая неделя в течение года, начинающегося с этой даты\n",
        "* **Day integer**: день\n",
        "* **Month integer**: месяц\n",
        "* **Year integer**: год\n",
        "* **PeriodOfDay**: период суток\n",
        "* **ForecastWindProduction**: прогнозируемая мощность ветра на этот период\n",
        "* **SystemLoadEA**: национальный прогноз нагрузки на этот период\n",
        "* **SMPEA**: прогноз цен на данный период\n",
        "* **ORKTemperature**: фактическая температура\n",
        "* **ORKWindspeed**: фактическая скорость ветра\n",
        "* **CO2Intensity**: фактическая интенсивность выбросов CO2 в произведенной электроэнергии (г/кВт*ч)\n",
        "* **ActualWindProduction**: фактическая нагрузка на национальную систему за этот период\n",
        "* **SystemLoadEP2**: фактическая цена за данный период времени, прогнозируемое значение.\n",
        "* **Target Variable: SystemLoadEP2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39HPNfv85H_n"
      },
      "source": [
        "## Создание бейзлайна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "m-pORWnM5CXy"
      },
      "outputs": [],
      "source": [
        "def simple_classification(df):\n",
        "  X_class = df.drop(['HealthImpactClass','HealthImpactScore','RecordID'], axis=1)\n",
        "  y_class = df['HealthImpactClass']\n",
        "\n",
        "  X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_class, X_test_class, y_train_class, y_test_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5lwB3iJ5J8I",
        "outputId": "ba3a4a7d-7406-49ca-f323-173f469c817c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность RandomForestClassifier: 0.8997\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = simple_classification(df_class)\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "accuracy_class = accuracy_score(y_test, predictions)\n",
        "print(f\"Точность RandomForestClassifier: {accuracy_class:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxHD8-l25Tkl"
      },
      "source": [
        "### Регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "KJnCQt475QMf"
      },
      "outputs": [],
      "source": [
        "def simple_regression(df):\n",
        "  X_reg = df.drop(['SMPEP2', 'DateTime','Holiday'], axis=1, errors='ignore')\n",
        "  y_reg = df['SMPEP2']\n",
        "\n",
        "  for col in X_reg.columns:\n",
        "      X_reg[col] = pd.to_numeric(X_reg[col], errors='coerce')\n",
        "\n",
        "  y_reg = pd.to_numeric(y_reg, errors='coerce')\n",
        "\n",
        "  X_reg = X_reg.fillna(0)\n",
        "  y_reg = y_reg.fillna(0)\n",
        "\n",
        "  X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_reg, X_test_reg, y_train_reg, y_test_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNtTOBd_5VBU",
        "outputId": "bb82d606-0e3f-4c1c-ab21-2ae130aed0ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднеквадратичная ошибка RandomForestRegressor: 470.4373\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = simple_regression(df_reg)\n",
        "\n",
        "model = RandomForestRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "mse_reg = mean_squared_error(y_test, predictions)\n",
        "print(f\"Среднеквадратичная ошибка RandomForestRegressor: {mse_reg:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx7vIx6f5qAe"
      },
      "source": [
        "## Улучшение бейзлайна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v23yQv9W5aeV"
      },
      "outputs": [],
      "source": [
        "def upgraded_classification(df):\n",
        "  df = df.drop(columns=[\"RecordID\"], errors=\"ignore\")\n",
        "\n",
        "  low_PM2_5 = df[\"PM2_5\"].quantile(0.25)\n",
        "  strong_PM2_5 = df[\"PM2_5\"].quantile(0.75)\n",
        "  df[\"LowPM2_5\"] = (df[\"PM2_5\"] <= low_PM2_5).astype(int)\n",
        "  df[\"StrongPM2_5\"] = (df[\"PM2_5\"] >= strong_PM2_5).astype(int)\n",
        "\n",
        "  low_PM10 = df[\"PM10\"].quantile(0.25)\n",
        "  strong_PM10 = df[\"PM10\"].quantile(0.75)\n",
        "  df[\"LowPM10\"] = (df[\"PM10\"] <= low_PM10).astype(int)\n",
        "  df[\"StrongPM10\"] = (df[\"PM10\"] >= strong_PM10).astype(int)\n",
        "\n",
        "\n",
        "  low_AQI = df[\"AQI\"].quantile(0.25)\n",
        "  strong_AQI = df[\"AQI\"].quantile(0.75)\n",
        "  df[\"LowAQI\"] = (df[\"AQI\"] <= low_AQI).astype(int)\n",
        "  df[\"StrongAQI\"] = (df[\"AQI\"] >= strong_AQI).astype(int)\n",
        "\n",
        "  df = df.drop(columns=[\"RespiratoryCases\", \"CardiovascularCases\",\"WindSpeed\",\"Temperature\",\"Humidity\",'PM2_5'], axis=1)\n",
        "\n",
        "  df = df[[\n",
        "      \"HealthImpactClass\",\n",
        "      \"LowAQI\",\n",
        "      \"LowPM2_5\",\n",
        "      \"LowPM10\",\n",
        "      \"StrongPM2_5\",\n",
        "      \"PM10\",\n",
        "      \"O3\",\n",
        "      \"StrongAQI\",\n",
        "      \"AQI\",\n",
        "      \"HealthImpactScore\"\n",
        "  ]]\n",
        "\n",
        "  X_class = df.drop(['HealthImpactClass','HealthImpactScore'], axis=1)\n",
        "  y_class = df['HealthImpactClass']\n",
        "\n",
        "  X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_class, X_test_class, y_train_class, y_test_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h-K6msPu5sYf"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_classification(df_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY5wI17W5uDU",
        "outputId": "73823390-797e-4231-9290-bc60ab6cb111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'bootstrap': True, 'criterion': 'log_loss', 'max_depth': 19, 'max_features': None, 'min_samples_leaf': 6, 'min_samples_split': 6, 'n_estimators': 165}\n",
            "Лучший score: 0.88960080509896\n",
            "Точность на тесте: 0.8876146788990825\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": randint(50, 300),\n",
        "    \"max_depth\": randint(3, 30),\n",
        "    \"min_samples_split\": randint(2, 20),\n",
        "    \"min_samples_leaf\": randint(1, 20),\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "    \"bootstrap\": [True, False],\n",
        "    \"criterion\": [\"gini\", \"entropy\", \"log_loss\"]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", random_search.best_params_)\n",
        "print(\"Лучший score:\", random_search.best_score_)\n",
        "\n",
        "print(\"Точность на тесте:\", random_search.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3CbV65J07BSf"
      },
      "source": [
        "### Регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "p0Iy6O7s6Lo1"
      },
      "outputs": [],
      "source": [
        "def upgraded_regression(df):\n",
        "  df['ForecastWindProduction'] = pd.to_numeric(df['ForecastWindProduction'], errors='coerce')\n",
        "  df['SystemLoadEA'] = pd.to_numeric(df['SystemLoadEA'], errors='coerce')\n",
        "  df['SMPEA'] = pd.to_numeric(df['SMPEA'], errors='coerce')\n",
        "  df['ORKTemperature'] = pd.to_numeric(df['ORKTemperature'], errors='coerce')\n",
        "  df['ORKWindspeed'] = pd.to_numeric(df['ORKWindspeed'], errors='coerce')\n",
        "  df['CO2Intensity'] = pd.to_numeric(df['CO2Intensity'], errors='coerce')\n",
        "  df['ActualWindProduction'] = pd.to_numeric(df['ActualWindProduction'], errors='coerce')\n",
        "  df['SystemLoadEP2'] = pd.to_numeric(df['SystemLoadEP2'], errors='coerce')\n",
        "  df['SMPEP2'] = pd.to_numeric(df['SMPEP2'], errors='coerce')\n",
        "\n",
        "  df = df.drop([\"DateTime\",\"Holiday\"],axis = 1)\n",
        "\n",
        "  df = df.dropna()\n",
        "\n",
        "  df = df[df['SMPEP2'] > 0]\n",
        "  df = df[df['SMPEP2'] != 1000]\n",
        "\n",
        "  X_reg = df.drop(['SMPEP2'], axis=1, errors='ignore')\n",
        "  y_reg = df['SMPEP2']\n",
        "\n",
        "  X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_reg, X_test_reg, y_train_reg, y_test_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xC3AkLCP7GE_"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_regression(df_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DArytUqS7KFb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "784beee5-70f1-4dcb-e4c2-bedcb82d29ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'max_depth': 26, 'min_samples_split': 4, 'n_estimators': 249}\n",
            "Лучший MSE: 489.6096713909945\n",
            "MSE на тесте: 433.5225540991735\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestRegressor(random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": randint(100, 500),\n",
        "    \"max_depth\": randint(3, 30),\n",
        "    \"min_samples_split\": randint(2, 20)\n",
        "}\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=5,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", random_search.best_params_)\n",
        "print(\"Лучший MSE:\", -random_search.best_score_)\n",
        "\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "print(\"MSE на тесте:\", mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CedwycSU9ITo"
      },
      "source": [
        "Стандартный бейзлайн:\n",
        "\n",
        "* Точность RandomForestClassifier: 0.8962\n",
        "* Среднеквадратичная ошибка (MSE) RandomForestRegressor: 476.6302\n",
        "\n",
        "Улучшенный байзлайн:\n",
        "\n",
        "* Точность RandomForestClassifier: 0.8876\n",
        "* Среднеквадратичная ошибка (MSE) RandomForestRegressor: 433.52"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbx5i6IG9ab5"
      },
      "source": [
        "## Имплементация алгоритма"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "s6obaMhc9RsP"
      },
      "outputs": [],
      "source": [
        "# Код дерева из Лабы №3\n",
        "class My_Decision_Tree_Classifier:\n",
        "    def __init__(self,\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "\n",
        "    def _gini(self, y):\n",
        "        m = len(y)\n",
        "        if m == 0:\n",
        "            return 0\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        p = counts / m\n",
        "        return 1 - np.sum(p * p)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_gini = 1e10\n",
        "        best_feat = None\n",
        "        best_thr = None\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_idx = X[:, feature].argsort()\n",
        "            X_f = X[sorted_idx, feature]\n",
        "            y_f = y[sorted_idx]\n",
        "\n",
        "            unique_vals = np.unique(X_f)\n",
        "            if len(unique_vals) == 1:\n",
        "                continue\n",
        "\n",
        "\n",
        "            left_counts = {}\n",
        "            right_counts = dict(zip(*np.unique(y_f, return_counts=True)))\n",
        "            left_n = 0\n",
        "            right_n = len(y_f)\n",
        "\n",
        "            for i in range(1, m):\n",
        "                cls = y_f[i - 1]\n",
        "\n",
        "\n",
        "                left_counts[cls] = left_counts.get(cls, 0) + 1\n",
        "                right_counts[cls] -= 1\n",
        "                left_n += 1\n",
        "                right_n -= 1\n",
        "\n",
        "                if X_f[i] == X_f[i - 1]:\n",
        "                    continue\n",
        "                if left_n < self.min_samples_leaf or right_n < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "\n",
        "                left_gini = 1.0\n",
        "                if left_n > 0:\n",
        "                    p = np.fromiter(left_counts.values(), dtype=float) / left_n\n",
        "                    left_gini = 1 - np.sum(p * p)\n",
        "\n",
        "                right_gini = 1.0\n",
        "                if right_n > 0:\n",
        "                    p = np.fromiter(right_counts.values(), dtype=float) / right_n\n",
        "                    right_gini = 1 - np.sum(p * p)\n",
        "\n",
        "                gini = (left_n * left_gini + right_n * right_gini) / m\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feat = feature\n",
        "                    best_thr = (X_f[i] + X_f[i - 1]) / 2\n",
        "\n",
        "        return best_feat, best_thr\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples = len(y)\n",
        "        num_labels = len(np.unique(y))\n",
        "\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
        "           num_labels == 1 or \\\n",
        "           num_samples < self.min_samples_split:\n",
        "            values, counts = np.unique(y, return_counts=True)\n",
        "            return {\"leaf\": True, \"class\": values[np.argmax(counts)]}\n",
        "\n",
        "        feat, thr = self._best_split(X, y)\n",
        "        if feat is None:\n",
        "            values, counts = np.unique(y, return_counts=True)\n",
        "            return {\"leaf\": True, \"class\": values[np.argmax(counts)]}\n",
        "\n",
        "        left_idx = X[:, feat] <= thr\n",
        "        right_idx = X[:, feat] > thr\n",
        "\n",
        "        return {\n",
        "            \"leaf\": False,\n",
        "            \"feature\": feat,\n",
        "            \"threshold\": thr,\n",
        "            \"left\": self._build_tree(X[left_idx], y[left_idx], depth + 1),\n",
        "            \"right\": self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        self.tree = self._build_tree(X, y)\n",
        "        return self\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        while not node[\"leaf\"]:\n",
        "            if x[node[\"feature\"]] <= node[\"threshold\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node[\"class\"]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
        "\n",
        "\n",
        "class My_Random_Forest_Classifier:\n",
        "    def __init__(self,\n",
        "                 n_estimators=100,\n",
        "                 max_features=\"sqrt\",\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 bootstrap=True,\n",
        "                 random_state=None):\n",
        "\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_features = max_features\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.bootstrap = bootstrap\n",
        "        self.random_state = random_state\n",
        "        self.trees = []\n",
        "        self.feature_indices = []\n",
        "\n",
        "        if self.random_state is not None:\n",
        "            np.random.seed(self.random_state)\n",
        "\n",
        "    def _slice_rows(self, X, idx):\n",
        "        if isinstance(X, np.ndarray):\n",
        "            return X[idx]\n",
        "        else:\n",
        "            return X.iloc[idx]\n",
        "\n",
        "    def _slice_cols(self, X, idx):\n",
        "        if isinstance(X, np.ndarray):\n",
        "            return X[:, idx]\n",
        "        else:\n",
        "            return X.iloc[:, idx]\n",
        "\n",
        "    def _sample_features(self, n_features):\n",
        "        if self.max_features == \"sqrt\":\n",
        "            k = int(np.sqrt(n_features))\n",
        "        elif self.max_features == \"log2\":\n",
        "            k = int(np.log2(n_features))\n",
        "        elif isinstance(self.max_features, int):\n",
        "            k = self.max_features\n",
        "        else:\n",
        "            k = n_features\n",
        "\n",
        "        return np.random.choice(n_features, k, replace=False)\n",
        "\n",
        "    def _bootstrap_sample(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        idx = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return self._slice_rows(X, idx), self._slice_rows(y, idx)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.trees = []\n",
        "        self.feature_indices = []\n",
        "\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            if self.bootstrap:\n",
        "                X_sample, y_sample = self._bootstrap_sample(X, y)\n",
        "            else:\n",
        "                X_sample, y_sample = X, y\n",
        "\n",
        "            feat_idx = self._sample_features(n_features)\n",
        "            self.feature_indices.append(feat_idx)\n",
        "\n",
        "            tree = My_Decision_Tree_Classifier(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split\n",
        "            )\n",
        "            tree.fit(self._slice_cols(X_sample, feat_idx), y_sample)\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "\n",
        "        for tree, feat_idx in zip(self.trees, self.feature_indices):\n",
        "            preds = tree.predict(self._slice_cols(X, feat_idx))\n",
        "            predictions.append(preds)\n",
        "\n",
        "        predictions = np.array(predictions).T\n",
        "\n",
        "        final_preds = []\n",
        "        for row in predictions:\n",
        "            final_preds.append(Counter(row).most_common(1)[0][0])\n",
        "\n",
        "        return np.array(final_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WYX8wKkx9UKj"
      },
      "outputs": [],
      "source": [
        "# Код дерева из Лабы №3\n",
        "class My_Decision_Tree_Regressor:\n",
        "    def __init__(self,\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "\n",
        "    def _variance(self, y):\n",
        "        return np.var(y) if len(y) > 0 else 0\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_feat, best_thr = None, None\n",
        "        best_var = 1e18\n",
        "\n",
        "        total_sum = y.sum()\n",
        "        total_sq_sum = np.dot(y, y)\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_idx = np.argsort(X[:, feature])\n",
        "            X_f = X[sorted_idx, feature]\n",
        "            y_f = y[sorted_idx]\n",
        "\n",
        "            left_sum = 0.0\n",
        "            left_sq_sum = 0.0\n",
        "            left_n = 0\n",
        "\n",
        "\n",
        "            right_sum = total_sum\n",
        "            right_sq_sum = total_sq_sum\n",
        "            right_n = m\n",
        "\n",
        "            for i in range(1, m):\n",
        "                yi = y_f[i - 1]\n",
        "\n",
        "\n",
        "                left_sum += yi\n",
        "                left_sq_sum += yi * yi\n",
        "                left_n += 1\n",
        "\n",
        "                right_sum -= yi\n",
        "                right_sq_sum -= yi * yi\n",
        "                right_n -= 1\n",
        "\n",
        "\n",
        "                if X_f[i] == X_f[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                if left_n < self.min_samples_leaf or right_n < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "\n",
        "                left_var = left_sq_sum / left_n - (left_sum / left_n)**2\n",
        "\n",
        "                right_var = right_sq_sum / right_n - (right_sum / right_n)**2\n",
        "\n",
        "\n",
        "                weighted_var = left_n * left_var + right_n * right_var\n",
        "\n",
        "                if weighted_var < best_var:\n",
        "                    best_var = weighted_var\n",
        "                    best_feat = feature\n",
        "                    best_thr = (X_f[i] + X_f[i - 1]) / 2\n",
        "\n",
        "        return best_feat, best_thr\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        m = len(y)\n",
        "\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
        "           m < self.min_samples_split or \\\n",
        "           np.var(y) < 1e-10:\n",
        "            return {\"leaf\": True, \"value\": np.mean(y)}\n",
        "\n",
        "        feat, thr = self._best_split(X, y)\n",
        "\n",
        "        if feat is None:\n",
        "            return {\"leaf\": True, \"value\": np.mean(y)}\n",
        "\n",
        "        left_idx = X[:, feat] <= thr\n",
        "        right_idx = ~left_idx\n",
        "\n",
        "        return {\n",
        "            \"leaf\": False,\n",
        "            \"feature\": feat,\n",
        "            \"threshold\": thr,\n",
        "            \"left\": self._build_tree(X[left_idx], y[left_idx], depth + 1),\n",
        "            \"right\": self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "        }\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = np.array(X), np.array(y, dtype=float)\n",
        "        self.tree = self._build_tree(X, y)\n",
        "        return self\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        while not node[\"leaf\"]:\n",
        "            if x[node[\"feature\"]] <= node[\"threshold\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node[\"value\"]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
        "\n",
        "\n",
        "class My_Random_Forest_Regressor:\n",
        "    def __init__(self,\n",
        "                 n_estimators=100,\n",
        "                 max_features=\"sqrt\",\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 bootstrap=True,\n",
        "                 random_state=None):\n",
        "\n",
        "        self.n_estimators = n_estimators\n",
        "        self.max_features = max_features\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.bootstrap = bootstrap\n",
        "        self.random_state = random_state\n",
        "\n",
        "        self.trees = []\n",
        "        self.feature_indices = []\n",
        "\n",
        "        if random_state is not None:\n",
        "            np.random.seed(random_state)\n",
        "\n",
        "    def _slice_rows(self, X, idx):\n",
        "        if isinstance(X, np.ndarray):\n",
        "            return X[idx]\n",
        "        else:\n",
        "            return X.iloc[idx]\n",
        "\n",
        "    def _slice_cols(self, X, idx):\n",
        "        if isinstance(X, np.ndarray):\n",
        "            return X[:, idx]\n",
        "        else:\n",
        "            return X.iloc[:, idx]\n",
        "\n",
        "    def _sample_features(self, n_features):\n",
        "        if self.max_features == \"sqrt\":\n",
        "            k = int(np.sqrt(n_features))\n",
        "        elif self.max_features == \"log2\":\n",
        "            k = int(np.log2(n_features))\n",
        "        elif isinstance(self.max_features, int):\n",
        "            k = self.max_features\n",
        "        else:\n",
        "            k = n_features\n",
        "\n",
        "        return np.random.choice(n_features, k, replace=False)\n",
        "\n",
        "    def _bootstrap_sample(self, X, y):\n",
        "        n_samples = X.shape[0]\n",
        "        idx = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        return self._slice_rows(X, idx), self._slice_rows(y, idx)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        self.trees = []\n",
        "        self.feature_indices = []\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            if self.bootstrap:\n",
        "                X_sample, y_sample = self._bootstrap_sample(X, y)\n",
        "            else:\n",
        "                X_sample, y_sample = X, y\n",
        "\n",
        "            feat_idx = self._sample_features(n_features)\n",
        "            self.feature_indices.append(feat_idx)\n",
        "\n",
        "            tree = My_Decision_Tree_Regressor(\n",
        "                max_depth=self.max_depth,\n",
        "                min_samples_split=self.min_samples_split\n",
        "            )\n",
        "\n",
        "            tree.fit(self._slice_cols(X_sample, feat_idx), y_sample)\n",
        "\n",
        "            self.trees.append(tree)\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = []\n",
        "\n",
        "        for tree, feat_idx in zip(self.trees, self.feature_indices):\n",
        "            p = tree.predict(self._slice_cols(X, feat_idx))\n",
        "            preds.append(p)\n",
        "\n",
        "        preds = np.array(preds)\n",
        "        return np.mean(preds, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_classification(df_class)\n",
        "\n",
        "model = My_Random_Forest_Classifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "accuracy_class = accuracy_score(y_test, predictions)\n",
        "print(f\"Точность My_Random_Forest_Classifier: {accuracy_class:.4f}\")"
      ],
      "metadata": {
        "id": "WGmZNoRAt_V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c250b48d-16dd-488e-c1b3-d48a98bb4a0e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность My_Random_Forest_Classifier: 0.8268\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_regression(df_reg)\n",
        "\n",
        "model = My_Random_Forest_Regressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "mse_reg = mean_squared_error(y_test, predictions)\n",
        "print(f\"Среднеквадратичная ошибка My_Random_Forest_Regressor: {mse_reg:.4f}\")"
      ],
      "metadata": {
        "id": "cZ-SKwR1vOE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9afab2e2-00db-4131-e8f6-a1e809b8ad43"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднеквадратичная ошибка My_Random_Forest_Regressor: 677.0049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_classification(df_class)"
      ],
      "metadata": {
        "id": "k1J3FwVUvULb"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_params(type_task, my_model,\n",
        "                  X_train, X_test, y_train, y_test,\n",
        "                  n_estimators=(250, 500),\n",
        "                  max_depth=(15, 18),\n",
        "                  min_samples_split=(3, 5)):\n",
        "\n",
        "    best_score = -1e18 if type_task == 'clf' else 1e18\n",
        "    best_params = None\n",
        "\n",
        "    for n_est in n_estimators:\n",
        "        for depth in max_depth:\n",
        "            for splt in min_samples_split:\n",
        "\n",
        "                model = my_model(\n",
        "                    n_estimators=n_est,\n",
        "                    max_depth=depth,\n",
        "                    min_samples_split=splt,\n",
        "                )\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "                preds = model.predict(X_test)\n",
        "\n",
        "                if type_task == 'clf':\n",
        "                    score = accuracy_score(y_test, preds)\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_params = (n_est, depth, splt)\n",
        "\n",
        "                else:\n",
        "                    score = mean_squared_error(y_test, preds)\n",
        "                    if score < best_score:\n",
        "                        best_score = score\n",
        "                        best_params = (n_est, depth, splt)\n",
        "\n",
        "    return best_score, best_params\n"
      ],
      "metadata": {
        "id": "bEDP_avrvYgf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc, best_params = search_params('clf',My_Random_Forest_Classifier,X_train,X_test,y_train,y_test)\n",
        "print(f\"Лучшая точность My_Random_Forest_Classifier: {acc:.4f}\")\n",
        "print(f\"Best params: max_depth={best_params[0]}, min_sample_split={best_params[1]}, min_sample_leaf={best_params[2]}\")"
      ],
      "metadata": {
        "id": "cW1AFrdRUH6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e307874-06ae-4c92-ab10-ad23808bf77c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая точность My_Random_Forest_Classifier: 0.8268\n",
            "Best params: max_depth=250, min_sample_split=15, min_sample_leaf=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_regression(df_reg)"
      ],
      "metadata": {
        "id": "XzxfbdpYeVfn"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse, best_params = search_params('reg',My_Random_Forest_Regressor,X_train,X_test,y_train,y_test)\n",
        "print(f\"Лучшая среднеквадратичная ошибка My_Random_Forest_Regressor: {mse:.4f}\")\n",
        "print(f\"Best params: n_estimators={best_params[0]}, max_depth={best_params[1]}, min_samples_split={best_params[2]}\")"
      ],
      "metadata": {
        "id": "xHyrw7tbUX-y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659f0571-2df9-4c8e-ff85-82c8530b8fb7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая среднеквадратичная ошибка My_Random_Forest_Regressor: 671.4459\n",
            "Best params: n_estimators=250, max_depth=18, min_samples_split=3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стандартный бейзлайн:\n",
        "\n",
        "Библиотечная реализация:\n",
        "* Точность RandomForestClassifier: 0.8962\n",
        "* Среднеквадратичная ошибка RandomForestRegressor: 476.6302\n",
        "\n",
        "Имплементация алгоритма:\n",
        "* Точность My_Random_Forest_Classifier: 0.8268\n",
        "* Среднеквадратичная ошибка My_Random_Forest_Regressor: 677.0049\n",
        "\n",
        "Улучшенный байзлайн:\n",
        "\n",
        "Библиотечная реализация:\n",
        "* Точность RandomForestClassifier: 0.8876\n",
        "* Среднеквадратичная ошибка RandomForestRegressor: 433.52\n",
        "\n",
        "Имплементация алгоритма:\n",
        "* точность My_Random_Forest_Classifier: 0.8268\n",
        "* среднеквадратичная ошибка My_Random_Forest_Regressor: 671.4459\n",
        "\n",
        "Итог: Библиотечные модели демонстрируют высокое качество предсказаний, особенно для регрессии, и реагируют на улучшение бейзлайна снижением ошибки.\n",
        "\n",
        "Собственная реализация алгоритма показала стабильную, но более низкую точность по сравнению с библиотечными моделями, с незначительным улучшением в регрессии.\n",
        "\n",
        "Итоги подтверждают, что для практических задач библиотечные реализации Random Forest обеспечивают более высокую точность и надёжность, тогда как самостоятельная реализация требует дополнительной оптимизации для достижения сопоставимого качества."
      ],
      "metadata": {
        "id": "e8U0NXOvcRzD"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IGbhqBKEg2or"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}