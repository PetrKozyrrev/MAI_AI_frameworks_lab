{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0QaYASmSyHdS"
      },
      "source": [
        "# Лабораторная работа №5 (Проведение исследований с градиентным бустингом)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tSRA-HEUxzmo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sc7qSyBLyl5S"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "\n",
        "# Игнорировать все предупреждения\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OTrjHyhJyqvJ"
      },
      "outputs": [],
      "source": [
        "df_class = pd.read_csv('classification.csv')\n",
        "df_reg = pd.read_csv('regression.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMwWciLWyzzV"
      },
      "source": [
        "Датасет для классификации (Air Quality & Health Impact Analysis):\n",
        "* **RecordID:** Уникальный идентификатор, присваиваемый каждой записи\n",
        "* **AQI:** Индекс качества воздуха, показывающий, насколько загрязнен воздух в настоящее время или насколько загрязненным он, по прогнозам, станет в будущем\n",
        "* **PM10**:  Концентрация твердых частиц диаметром менее 10 микрометров (μg/m³)\n",
        "* **PM2_5**: Концентрация твердых частиц диаметром менее 2,5 микрометров (μg/m³)\n",
        "* **NO2**: Концентрация диоксида азота (ppb)\n",
        "* **SO2**: Концентрация диоксида серы (ppb)\n",
        "* **O3**: Концентрация озона (ppb)\n",
        "* **Temperature**: Температура в градусах Цельсия (°C)\n",
        "* **Humidity**: Процент влажности (%)\n",
        "* **WindSpeed**: Скорость ветра (m/s)\n",
        "* **RespiratoryCases**: Количество зарегистрированных респираторных случаев.\n",
        "* **CardiovascularCases**: Количество зарегистрированных сердечно-сосудистых случаев\n",
        "* **HospitalAdmissions**: Количество зарегистрированных случаев госпитализации\n",
        "* **Target Variable: HealthImpactClass**\n",
        "\n",
        "Датасет для регрессии (Electrity Prices):\n",
        "* **DateTime**: дата и время\n",
        "* **Holiday**: название праздника, если день нерабочий день\n",
        "* **HolidayFlag**: целое число, 1, если день нерабочий день, ноль в противном случае\n",
        "* **DayOfWeek**: целое число (0-6), 0 понедельник, день недели\n",
        "* **WeekOfYear**: текущая неделя в течение года, начинающегося с этой даты\n",
        "* **Day integer**: день\n",
        "* **Month integer**: месяц\n",
        "* **Year integer**: год\n",
        "* **PeriodOfDay**: период суток\n",
        "* **ForecastWindProduction**: прогнозируемая мощность ветра на этот период\n",
        "* **SystemLoadEA**: национальный прогноз нагрузки на этот период\n",
        "* **SMPEA**: прогноз цен на данный период\n",
        "* **ORKTemperature**: фактическая температура\n",
        "* **ORKWindspeed**: фактическая скорость ветра\n",
        "* **CO2Intensity**: фактическая интенсивность выбросов CO2 в произведенной электроэнергии (г/кВт*ч)\n",
        "* **ActualWindProduction**: фактическая нагрузка на национальную систему за этот период\n",
        "* **SystemLoadEP2**: фактическая цена за данный период времени, прогнозируемое значение.\n",
        "* **Target Variable: SystemLoadEP2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-PlrHdqy2aa"
      },
      "source": [
        "## Создание бейзлайна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mk0KZhynywg0"
      },
      "outputs": [],
      "source": [
        "def simple_classification(df):\n",
        "  X_class = df.drop(['HealthImpactClass','HealthImpactScore','RecordID'], axis=1)\n",
        "  y_class = df['HealthImpactClass']\n",
        "\n",
        "  X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_class, X_test_class, y_train_class, y_test_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dR6Rl-Ndy5nS",
        "outputId": "ef289a90-0b7f-4820-9cbd-7e745815d554"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность GradientBoostingClassifier: 0.8899\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = simple_classification(df_class)\n",
        "\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Оценка качества модели\n",
        "accuracy_class = accuracy_score(y_test, predictions)\n",
        "print(f\"Точность GradientBoostingClassifier: {accuracy_class:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DD7UlTZlzFau"
      },
      "source": [
        "### Регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EvY5ls3_y9hz"
      },
      "outputs": [],
      "source": [
        "def simple_regression(df):\n",
        "  X_reg = df.drop(['SMPEP2', 'DateTime','Holiday'], axis=1, errors='ignore')\n",
        "  y_reg = df['SMPEP2']\n",
        "\n",
        "  for col in X_reg.columns:\n",
        "      X_reg[col] = pd.to_numeric(X_reg[col], errors='coerce')\n",
        "\n",
        "  y_reg = pd.to_numeric(y_reg, errors='coerce')\n",
        "\n",
        "  X_reg = X_reg.fillna(0)\n",
        "  y_reg = y_reg.fillna(0)\n",
        "\n",
        "  X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_reg, X_test_reg, y_train_reg, y_test_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IG4WCLQszHKq",
        "outputId": "b1374a60-63e7-4c86-af27-df3969f64485"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднеквадратичная ошибка GradientBoostingRegressor: 582.0431\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = simple_regression(df_reg)\n",
        "\n",
        "model = GradientBoostingRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "mse_reg = mean_squared_error(y_test, predictions)\n",
        "print(f\"Среднеквадратичная ошибка GradientBoostingRegressor: {mse_reg:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yA8cA-39zUus"
      },
      "source": [
        "## Улучшение бейзлайна"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "JC7_d7uwzLlu"
      },
      "outputs": [],
      "source": [
        "def upgraded_classification(df):\n",
        "  df = df.drop(columns=[\"RecordID\"], errors=\"ignore\")\n",
        "\n",
        "  low_PM2_5 = df[\"PM2_5\"].quantile(0.25)\n",
        "  strong_PM2_5 = df[\"PM2_5\"].quantile(0.75)\n",
        "  df[\"LowPM2_5\"] = (df[\"PM2_5\"] <= low_PM2_5).astype(int)\n",
        "  df[\"StrongPM2_5\"] = (df[\"PM2_5\"] >= strong_PM2_5).astype(int)\n",
        "\n",
        "  low_PM10 = df[\"PM10\"].quantile(0.25)\n",
        "  strong_PM10 = df[\"PM10\"].quantile(0.75)\n",
        "  df[\"LowPM10\"] = (df[\"PM10\"] <= low_PM10).astype(int)\n",
        "  df[\"StrongPM10\"] = (df[\"PM10\"] >= strong_PM10).astype(int)\n",
        "\n",
        "\n",
        "  low_AQI = df[\"AQI\"].quantile(0.25)\n",
        "  strong_AQI = df[\"AQI\"].quantile(0.75)\n",
        "  df[\"LowAQI\"] = (df[\"AQI\"] <= low_AQI).astype(int)\n",
        "  df[\"StrongAQI\"] = (df[\"AQI\"] >= strong_AQI).astype(int)\n",
        "\n",
        "  df = df.drop(columns=[\"RespiratoryCases\", \"CardiovascularCases\",\"WindSpeed\",\"Temperature\",\"Humidity\",'PM2_5'], axis=1)\n",
        "\n",
        "  df = df[[\n",
        "      \"HealthImpactClass\",\n",
        "      \"LowAQI\",\n",
        "      \"LowPM2_5\",\n",
        "      \"LowPM10\",\n",
        "      \"StrongPM2_5\",\n",
        "      \"PM10\",\n",
        "      \"O3\",\n",
        "      \"StrongAQI\",\n",
        "      \"AQI\",\n",
        "      \"HealthImpactScore\"\n",
        "  ]]\n",
        "\n",
        "  X_class = df.drop(['HealthImpactClass','HealthImpactScore'], axis=1)\n",
        "  y_class = df['HealthImpactClass']\n",
        "\n",
        "  X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_class, X_test_class, y_train_class, y_test_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "VI98BzTTzWqn"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_classification(df_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV6bSbIBzYPZ",
        "outputId": "a397508b-a784-4b60-d389-9853e880ef2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'learning_rate': np.float64(0.16742692948967136), 'max_depth': 5, 'min_samples_leaf': 17, 'min_samples_split': 28, 'n_estimators': 108}\n",
            "Лучший score: 0.8785343209697454\n",
            "Точность на тесте: 0.8715596330275229\n"
          ]
        }
      ],
      "source": [
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": randint(50, 400),\n",
        "    \"learning_rate\": uniform(0.01, 0.3),\n",
        "    \"max_depth\": randint(2, 10),\n",
        "    \"min_samples_split\": randint(2, 30),\n",
        "    \"min_samples_leaf\": randint(1, 20),\n",
        "}\n",
        "\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=gb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    scoring=\"accuracy\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Лучшие параметры:\", random_search.best_params_)\n",
        "print(\"Лучший score:\", random_search.best_score_)\n",
        "\n",
        "print(\"Точность на тесте:\", random_search.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwxNHpvw0V5S"
      },
      "source": [
        "### Регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FXNq7giKz_nt"
      },
      "outputs": [],
      "source": [
        "def upgraded_regression(df):\n",
        "  df['ForecastWindProduction'] = pd.to_numeric(df['ForecastWindProduction'], errors='coerce')\n",
        "  df['SystemLoadEA'] = pd.to_numeric(df['SystemLoadEA'], errors='coerce')\n",
        "  df['SMPEA'] = pd.to_numeric(df['SMPEA'], errors='coerce')\n",
        "  df['ORKTemperature'] = pd.to_numeric(df['ORKTemperature'], errors='coerce')\n",
        "  df['ORKWindspeed'] = pd.to_numeric(df['ORKWindspeed'], errors='coerce')\n",
        "  df['CO2Intensity'] = pd.to_numeric(df['CO2Intensity'], errors='coerce')\n",
        "  df['ActualWindProduction'] = pd.to_numeric(df['ActualWindProduction'], errors='coerce')\n",
        "  df['SystemLoadEP2'] = pd.to_numeric(df['SystemLoadEP2'], errors='coerce')\n",
        "  df['SMPEP2'] = pd.to_numeric(df['SMPEP2'], errors='coerce')\n",
        "\n",
        "  df = df.drop([\"DateTime\",\"Holiday\"],axis = 1)\n",
        "\n",
        "  df = df.dropna()\n",
        "\n",
        "  df = df[df['SMPEP2'] > 0]\n",
        "  df = df[df['SMPEP2'] != 1000]\n",
        "\n",
        "  X_reg = df.drop(['SMPEP2'], axis=1, errors='ignore')\n",
        "  y_reg = df['SMPEP2']\n",
        "\n",
        "  X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_reg, X_test_reg, y_train_reg, y_test_reg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "1Wy9fL8k0XiT"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_regression(df_reg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LIUVoL8e0c0z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba097891-8adc-4b1d-86d6-f9a25df2dacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'learning_rate': np.float64(0.14777466758976016), 'max_depth': 6, 'min_samples_leaf': 4, 'min_samples_split': 9, 'n_estimators': 201}\n",
            "Лучший MSE: 549.5792531861805\n",
            "MSE на тесте: 504.2124933255265\n"
          ]
        }
      ],
      "source": [
        "gbr = GradientBoostingRegressor(random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": randint(50, 400),\n",
        "    \"learning_rate\": uniform(0.01, 0.3),\n",
        "    \"max_depth\": randint(2, 10),\n",
        "    \"min_samples_split\": randint(2, 30),\n",
        "    \"min_samples_leaf\": randint(1, 20),\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=gbr,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=5,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", random_search.best_params_)\n",
        "print(\"Лучший MSE:\", -random_search.best_score_)\n",
        "\n",
        "y_pred = random_search.predict(X_test)\n",
        "print(\"MSE на тесте:\", mean_squared_error(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Имплементация алгоритма"
      ],
      "metadata": {
        "id": "faqTgbWagTr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Decision_Tree_Regressor:\n",
        "    def __init__(self,\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "\n",
        "    def _variance(self, y):\n",
        "        return np.var(y) if len(y) > 0 else 0\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_feat, best_thr = None, None\n",
        "        best_var = 1e18\n",
        "\n",
        "        total_sum = y.sum()\n",
        "        total_sq_sum = np.dot(y, y)\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_idx = np.argsort(X[:, feature])\n",
        "            X_f = X[sorted_idx, feature]\n",
        "            y_f = y[sorted_idx]\n",
        "\n",
        "            left_sum = 0.0\n",
        "            left_sq_sum = 0.0\n",
        "            left_n = 0\n",
        "\n",
        "\n",
        "            right_sum = total_sum\n",
        "            right_sq_sum = total_sq_sum\n",
        "            right_n = m\n",
        "\n",
        "            for i in range(1, m):\n",
        "                yi = y_f[i - 1]\n",
        "\n",
        "\n",
        "                left_sum += yi\n",
        "                left_sq_sum += yi * yi\n",
        "                left_n += 1\n",
        "\n",
        "                right_sum -= yi\n",
        "                right_sq_sum -= yi * yi\n",
        "                right_n -= 1\n",
        "\n",
        "\n",
        "                if X_f[i] == X_f[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                if left_n < self.min_samples_leaf or right_n < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "\n",
        "                left_var = left_sq_sum / left_n - (left_sum / left_n)**2\n",
        "\n",
        "                right_var = right_sq_sum / right_n - (right_sum / right_n)**2\n",
        "\n",
        "\n",
        "                weighted_var = left_n * left_var + right_n * right_var\n",
        "\n",
        "                if weighted_var < best_var:\n",
        "                    best_var = weighted_var\n",
        "                    best_feat = feature\n",
        "                    best_thr = (X_f[i] + X_f[i - 1]) / 2\n",
        "\n",
        "        return best_feat, best_thr\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        m = len(y)\n",
        "\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
        "           m < self.min_samples_split or \\\n",
        "           np.var(y) < 1e-10:\n",
        "            return {\"leaf\": True, \"value\": np.mean(y)}\n",
        "\n",
        "        feat, thr = self._best_split(X, y)\n",
        "\n",
        "        if feat is None:\n",
        "            return {\"leaf\": True, \"value\": np.mean(y)}\n",
        "\n",
        "        left_idx = X[:, feat] <= thr\n",
        "        right_idx = ~left_idx\n",
        "\n",
        "        return {\n",
        "            \"leaf\": False,\n",
        "            \"feature\": feat,\n",
        "            \"threshold\": thr,\n",
        "            \"left\": self._build_tree(X[left_idx], y[left_idx], depth + 1),\n",
        "            \"right\": self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "        }\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = np.array(X), np.array(y, dtype=float)\n",
        "        self.tree = self._build_tree(X, y)\n",
        "        return self\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        while not node[\"leaf\"]:\n",
        "            if x[node[\"feature\"]] <= node[\"threshold\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node[\"value\"]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.tree) for x in X])\n",
        "\n",
        "\n",
        "class My_Gradient_Boosting_Classifier:\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "        self.F0 = None\n",
        "\n",
        "    def _sigmoid(self, x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        y = y.astype(float)\n",
        "\n",
        "        p = np.clip(y.mean(), 1e-6, 1 - 1e-6)\n",
        "        self.F0 = np.log(p / (1 - p))\n",
        "\n",
        "        F = np.full(y.shape, self.F0)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            prob = self._sigmoid(F)\n",
        "\n",
        "            residual = y - prob\n",
        "\n",
        "            tree = My_Decision_Tree_Regressor(max_depth=self.max_depth)\n",
        "            tree.fit(X, residual)\n",
        "\n",
        "            self.trees.append(tree)\n",
        "\n",
        "            F += self.learning_rate * tree.predict(X)\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        F = np.full(X.shape[0], self.F0)\n",
        "\n",
        "        for tree in self.trees:\n",
        "            F += self.learning_rate * tree.predict(X)\n",
        "\n",
        "        return self._sigmoid(F)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (self.predict_proba(X) >= 0.5).astype(int)"
      ],
      "metadata": {
        "id": "3j57Vuh2gNWh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Gradient_Boosting_Regressor:\n",
        "    def __init__(self, n_estimators=100, learning_rate=0.1, max_depth=3):\n",
        "        self.n_estimators = n_estimators\n",
        "        self.learning_rate = learning_rate\n",
        "        self.max_depth = max_depth\n",
        "        self.trees = []\n",
        "        self.F0 = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        y = y.astype(float)\n",
        "\n",
        "        self.F0 = y.mean()\n",
        "\n",
        "        F = np.full(y.shape, self.F0)\n",
        "\n",
        "        for _ in range(self.n_estimators):\n",
        "            residual = y - F\n",
        "\n",
        "            tree = My_Decision_Tree_Regressor(max_depth=self.max_depth)\n",
        "            tree.fit(X, residual)\n",
        "\n",
        "            self.trees.append(tree)\n",
        "\n",
        "            F += self.learning_rate * tree.predict(X)\n",
        "\n",
        "    def predict(self, X):\n",
        "        F = np.full(X.shape[0], self.F0)\n",
        "\n",
        "        for tree in self.trees:\n",
        "            F += self.learning_rate * tree.predict(X)\n",
        "\n",
        "        return F"
      ],
      "metadata": {
        "id": "lBDo9jl_g-_s"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_classification(df_class)\n",
        "\n",
        "model = My_Gradient_Boosting_Classifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "accuracy_class = accuracy_score(y_test, predictions)\n",
        "print(f\"Точность My_Gradient_Boosting_Classifier: {accuracy_class:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5LERoUTh5oq",
        "outputId": "71143dc7-6c21-4d0a-85e2-7fd8ec5b12f0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность My_Gradient_Boosting_Classifier: 0.8578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_regression(df_reg)\n",
        "\n",
        "model = My_Gradient_Boosting_Regressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "mse_reg = mean_squared_error(y_test, predictions)\n",
        "print(f\"Среднеквадратичная ошибка  My_Gradient_Boosting_Regressor: {mse_reg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bgz1P_1iJV4",
        "outputId": "b13cbeb3-4418-4e63-b70c-55bacce06c55"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднеквадратичная ошибка  My_Gradient_Boosting_Regressor: 584.7498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_classification(df_class)"
      ],
      "metadata": {
        "id": "neJYJ0jRiQ1B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_params(type_task, my_model,\n",
        "                  X_train, X_test, y_train, y_test,\n",
        "                  n_estimators=(250, 500),\n",
        "                  max_depth=(3, 7)):\n",
        "\n",
        "    best_score = -1e18 if type_task == 'clf' else 1e18\n",
        "    best_params = None\n",
        "\n",
        "    for n_est in n_estimators:\n",
        "        for depth in max_depth:\n",
        "              model = my_model(\n",
        "                  n_estimators=n_est,\n",
        "                  max_depth=depth\n",
        "              )\n",
        "\n",
        "              model.fit(X_train, y_train)\n",
        "              preds = model.predict(X_test)\n",
        "\n",
        "              if type_task == 'clf':\n",
        "                  score = accuracy_score(y_test, preds)\n",
        "                  if score > best_score:\n",
        "                      best_score = score\n",
        "                      best_params = (n_est, depth)\n",
        "\n",
        "              else:\n",
        "                  score = mean_squared_error(y_test, preds)\n",
        "                  if score < best_score:\n",
        "                      best_score = score\n",
        "                      best_params = (n_est, depth)\n",
        "\n",
        "    return best_score, best_params\n"
      ],
      "metadata": {
        "id": "TUyiY8XpiSyf"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc, best_params = search_params('clf',My_Gradient_Boosting_Classifier,X_train,X_test,y_train,y_test)\n",
        "print(f\"Лучшая точность My_Gradient_Boosting_Classifier: {acc:.4f}\")\n",
        "print(f\"Best params: n_estimators={best_params[0]}, max_depth={best_params[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecmkAR2DicUM",
        "outputId": "ec6ffa27-f784-407e-a6d6-3602a272fa61"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая точность My_Gradient_Boosting_Classifier: 0.8549\n",
            "Best params: n_estimators=250, max_depth=7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_regression(df_reg)"
      ],
      "metadata": {
        "id": "W7uXPWZsijo3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7QuBJhhGozUK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mse, best_params = search_params('reg',My_Gradient_Boosting_Regressor,X_train,X_test,y_train,y_test)\n",
        "print(f\"Лучшая среднеквадратичная ошибка My_Gradient_Boosting_Regressor: {mse:.4f}\")\n",
        "print(f\"Best params: n_estimators={best_params[0]}, max_depth={best_params[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOKN-skkiem-",
        "outputId": "a27e20b1-eea9-473f-85dd-34d6d494f638"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая среднеквадратичная ошибка My_Gradient_Boosting_Regressor: 461.6550\n",
            "Best params: n_estimators=500, max_depth=7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стандартный бейзлайн:\n",
        "\n",
        "Библиотечная реализация:\n",
        "* Точность GradientBoostingClassifier: 0.8899\n",
        "* Среднеквадратичная ошибка GradientBoostingRegressor: 582.0431\n",
        "\n",
        "Имплементация алгоритма:\n",
        "* Точность My_Gradient_Boosting_Classifier: 0.8578\n",
        "* Среднеквадратичная ошибка My_Gradient_Boosting_Regressor: 584.7498\n",
        "\n",
        "Улучшенный байзлайн:\n",
        "\n",
        "Библиотечная реализация:\n",
        "* Точность GradientBoostingClassifier: 0.8715\n",
        "* Среднеквадратичная ошибка GradientBoostingRegressor: 504.212\n",
        "\n",
        "Имплементация алгоритма:\n",
        "* точность My_Gradient_Boosting_Classifier: 0.8549\n",
        "* среднеквадратичная ошибка My_Gradient_Boosting_Regressor: 461.6550\n",
        "\n",
        "Итог: Улучшенный бейзлайн положительно сказался на качестве регрессионных моделей в обоих подходах, особенно в собственной реализации.\n",
        "\n",
        "Для классификации наблюдается незначительное снижение точности у библиотечных моделей, тогда как собственная реализация остаётся стабильной.\n",
        "\n",
        "Библиотечные реализации Gradient Boosting показывают высокую точность и надёжность, однако собственная имплементация, при правильной настройке, также способна достичь значительного улучшения MSE для регрессии."
      ],
      "metadata": {
        "id": "9MOkK6VI8Rct"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hrkq2y7hnL9r"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}