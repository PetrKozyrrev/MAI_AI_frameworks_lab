{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №3 (Проведение исследований с решающим деревом)"
      ],
      "metadata": {
        "id": "9EsACstiVLSW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eMHCmcMcU38q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "\n",
        "# Игнорировать все предупреждения\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "GdB7GQlEVRUu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_class = pd.read_csv('classification.csv')\n",
        "df_reg = pd.read_csv('regression.csv')"
      ],
      "metadata": {
        "id": "zfEx1T94VSqE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Датасет для классификации (Air Quality & Health Impact Analysis):\n",
        "* **RecordID:** Уникальный идентификатор, присваиваемый каждой записи\n",
        "* **AQI:** Индекс качества воздуха, показывающий, насколько загрязнен воздух в настоящее время или насколько загрязненным он, по прогнозам, станет в будущем\n",
        "* **PM10**:  Концентрация твердых частиц диаметром менее 10 микрометров (μg/m³)\n",
        "* **PM2_5**: Концентрация твердых частиц диаметром менее 2,5 микрометров (μg/m³)\n",
        "* **NO2**: Концентрация диоксида азота (ppb)\n",
        "* **SO2**: Концентрация диоксида серы (ppb)\n",
        "* **O3**: Концентрация озона (ppb)\n",
        "* **Temperature**: Температура в градусах Цельсия (°C)\n",
        "* **Humidity**: Процент влажности (%)\n",
        "* **WindSpeed**: Скорость ветра (m/s)\n",
        "* **RespiratoryCases**: Количество зарегистрированных респираторных случаев.\n",
        "* **CardiovascularCases**: Количество зарегистрированных сердечно-сосудистых случаев\n",
        "* **HospitalAdmissions**: Количество зарегистрированных случаев госпитализации\n",
        "* **Target Variable: HealthImpactClass**\n",
        "\n",
        "Датасет для регрессии (Electrity Prices):\n",
        "* **DateTime**: дата и время\n",
        "* **Holiday**: название праздника, если день нерабочий день\n",
        "* **HolidayFlag**: целое число, 1, если день нерабочий день, ноль в противном случае\n",
        "* **DayOfWeek**: целое число (0-6), 0 понедельник, день недели\n",
        "* **WeekOfYear**: текущая неделя в течение года, начинающегося с этой даты\n",
        "* **Day integer**: день\n",
        "* **Month integer**: месяц\n",
        "* **Year integer**: год\n",
        "* **PeriodOfDay**: период суток\n",
        "* **ForecastWindProduction**: прогнозируемая мощность ветра на этот период\n",
        "* **SystemLoadEA**: национальный прогноз нагрузки на этот период\n",
        "* **SMPEA**: прогноз цен на данный период\n",
        "* **ORKTemperature**: фактическая температура\n",
        "* **ORKWindspeed**: фактическая скорость ветра\n",
        "* **CO2Intensity**: фактическая интенсивность выбросов CO2 в произведенной электроэнергии (г/кВт*ч)\n",
        "* **ActualWindProduction**: фактическая нагрузка на национальную систему за этот период\n",
        "* **SystemLoadEP2**: фактическая цена за данный период времени, прогнозируемое значение.\n",
        "* **Target Variable: SystemLoadEP2**"
      ],
      "metadata": {
        "id": "_VubWP8tVaC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание бейзлайна"
      ],
      "metadata": {
        "id": "CbGXWMjvVcI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_classification(df):\n",
        "  X_class = df.drop(['HealthImpactClass','HealthImpactScore','RecordID'], axis=1)\n",
        "  y_class = df['HealthImpactClass']\n",
        "\n",
        "  X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_class, X_test_class, y_train_class, y_test_class"
      ],
      "metadata": {
        "id": "aLGRxPjgVWmW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_classification(df_class)\n",
        "\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "accuracy_class = accuracy_score(y_test, predictions)\n",
        "print(f\"Точность DecisionTreeClassifier: {accuracy_class:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5dObeavVqRh",
        "outputId": "3c4a783a-b744-4662-c882-708253f831a3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность DecisionTreeClassifier: 0.8286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Регрессия"
      ],
      "metadata": {
        "id": "UjLt45-UWEbo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_regression(df):\n",
        "  X_reg = df.drop(['SMPEP2', 'DateTime','Holiday'], axis=1, errors='ignore')\n",
        "  y_reg = df['SMPEP2']\n",
        "\n",
        "  for col in X_reg.columns:\n",
        "      X_reg[col] = pd.to_numeric(X_reg[col], errors='coerce')\n",
        "\n",
        "  y_reg = pd.to_numeric(y_reg, errors='coerce')\n",
        "\n",
        "  X_reg = X_reg.fillna(0)\n",
        "  y_reg = y_reg.fillna(0)\n",
        "\n",
        "  X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_reg, X_test_reg, y_train_reg, y_test_reg"
      ],
      "metadata": {
        "id": "OA2xq1IoVzOe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_regression(df_reg)\n",
        "\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "mse_reg = mean_squared_error(y_test, predictions)\n",
        "print(f\"Среднеквадратичная ошибка (MSE) DecisionTreeRegressor: {mse_reg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd-LD1uNWSyt",
        "outputId": "fad2aa2c-1930-4c68-8efe-fd196b3439aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднеквадратичная ошибка (MSE) DecisionTreeRegressor: 890.9472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Улучшение бейзлайна"
      ],
      "metadata": {
        "id": "WlkZCdHiWcPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upgraded_classification(df):\n",
        "  df = df.drop(columns=[\"RecordID\"], errors=\"ignore\")\n",
        "\n",
        "  low_PM2_5 = df[\"PM2_5\"].quantile(0.25)\n",
        "  strong_PM2_5 = df[\"PM2_5\"].quantile(0.75)\n",
        "  df[\"LowPM2_5\"] = (df[\"PM2_5\"] <= low_PM2_5).astype(int)\n",
        "  df[\"StrongPM2_5\"] = (df[\"PM2_5\"] >= strong_PM2_5).astype(int)\n",
        "\n",
        "  low_PM10 = df[\"PM10\"].quantile(0.25)\n",
        "  strong_PM10 = df[\"PM10\"].quantile(0.75)\n",
        "  df[\"LowPM10\"] = (df[\"PM10\"] <= low_PM10).astype(int)\n",
        "  df[\"StrongPM10\"] = (df[\"PM10\"] >= strong_PM10).astype(int)\n",
        "\n",
        "\n",
        "  low_AQI = df[\"AQI\"].quantile(0.25)\n",
        "  strong_AQI = df[\"AQI\"].quantile(0.75)\n",
        "  df[\"LowAQI\"] = (df[\"AQI\"] <= low_AQI).astype(int)\n",
        "  df[\"StrongAQI\"] = (df[\"AQI\"] >= strong_AQI).astype(int)\n",
        "\n",
        "  df = df.drop(columns=[\"RespiratoryCases\", \"CardiovascularCases\",\"WindSpeed\",\"Temperature\",\"Humidity\",'PM2_5'], axis=1)\n",
        "\n",
        "  df = df[[\n",
        "      \"HealthImpactClass\",\n",
        "      \"LowAQI\",\n",
        "      \"LowPM2_5\",\n",
        "      \"LowPM10\",\n",
        "      \"StrongPM2_5\",\n",
        "      \"PM10\",\n",
        "      \"O3\",\n",
        "      \"StrongAQI\",\n",
        "      \"AQI\",\n",
        "      \"HealthImpactScore\"\n",
        "  ]]\n",
        "\n",
        "  X_class = df.drop(['HealthImpactClass','HealthImpactScore'], axis=1)\n",
        "  y_class = df['HealthImpactClass']\n",
        "\n",
        "  X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_class, X_test_class, y_train_class, y_test_class"
      ],
      "metadata": {
        "id": "kELxZCkgWZQ4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_classification(df_class)"
      ],
      "metadata": {
        "id": "ikjudSBkWg2T"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    \"max_depth\": randint(1, 20),\n",
        "    \"min_samples_split\": randint(2, 20),\n",
        "    \"min_samples_leaf\": randint(1, 20),\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
        "    \"criterion\": [\"gini\", \"entropy\"]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", random_search.best_params_)\n",
        "print(\"Лучший score:\", random_search.best_score_)\n",
        "\n",
        "print(\"Точность DecisionTreeClassifier с подбором гиперпараметров:\", random_search.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrTwSzesWkYH",
        "outputId": "e1c62571-4765-44f0-ddbc-9a8aa4e7b6e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'criterion': 'entropy', 'max_depth': 14, 'max_features': None, 'min_samples_leaf': 8, 'min_samples_split': 17}\n",
            "Лучший score: 0.8819813775533334\n",
            "Точность DecisionTreeClassifier с подбором гиперпараметров: 0.8818807339449541\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Регрессия"
      ],
      "metadata": {
        "id": "Pl2XKh0UXdT4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upgraded_regression(df):\n",
        "  df['ForecastWindProduction'] = pd.to_numeric(df['ForecastWindProduction'], errors='coerce')\n",
        "  df['SystemLoadEA'] = pd.to_numeric(df['SystemLoadEA'], errors='coerce')\n",
        "  df['SMPEA'] = pd.to_numeric(df['SMPEA'], errors='coerce')\n",
        "  df['ORKTemperature'] = pd.to_numeric(df['ORKTemperature'], errors='coerce')\n",
        "  df['ORKWindspeed'] = pd.to_numeric(df['ORKWindspeed'], errors='coerce')\n",
        "  df['CO2Intensity'] = pd.to_numeric(df['CO2Intensity'], errors='coerce')\n",
        "  df['ActualWindProduction'] = pd.to_numeric(df['ActualWindProduction'], errors='coerce')\n",
        "  df['SystemLoadEP2'] = pd.to_numeric(df['SystemLoadEP2'], errors='coerce')\n",
        "  df['SMPEP2'] = pd.to_numeric(df['SMPEP2'], errors='coerce')\n",
        "\n",
        "  df = df.drop([\"DateTime\",\"Holiday\"],axis = 1)\n",
        "\n",
        "  df = df.dropna()\n",
        "\n",
        "  df = df[df['SMPEP2'] > 0]\n",
        "  df = df[df['SMPEP2'] != 1000]\n",
        "\n",
        "  # Выделение таргета\n",
        "  X_reg = df.drop(['SMPEP2'], axis=1, errors='ignore')\n",
        "  y_reg = df['SMPEP2']\n",
        "\n",
        "  # Сплит данных на тренировочные и тестовые\n",
        "  X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.3, random_state=42)\n",
        "\n",
        "  return X_train_reg, X_test_reg, y_train_reg, y_test_reg"
      ],
      "metadata": {
        "id": "iCzp_DRyW-d-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_regression(df_reg)"
      ],
      "metadata": {
        "id": "iI6TizA2XiqE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "param_dist = {\n",
        "    \"max_depth\": randint(1, 30),\n",
        "    \"min_samples_split\": randint(2, 30),\n",
        "    \"min_samples_leaf\": randint(1, 30),\n",
        "    \"max_features\": [\"auto\", \"sqrt\", \"log2\", None],\n",
        "    \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring=\"neg_mean_squared_error\",\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Лучшие параметры:\", random_search.best_params_)\n",
        "print(\"Лучший MSE:\", -random_search.best_score_)\n",
        "\n",
        "print(\"MSE DecisionTreeRegressor с подбором гиперпараметров:\", random_search.score(X_test, y_test))"
      ],
      "metadata": {
        "id": "v18MhcD-Xk-M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958a879c-11f4-4740-d020-45993c77e4f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры: {'criterion': 'friedman_mse', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 22, 'min_samples_split': 19}\n",
            "Лучший MSE: 656.8294358347406\n",
            "MSE DecisionTreeRegressor с подбором гиперпараметров: -604.3770310606506\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стандартный бейзлайн:\n",
        "* Точность DecisionTreeClassifier: 0.8286\n",
        "* Среднеквадратичная ошибка DecisionTreeRegressor: 890.9472\n",
        "\n",
        "Улучшенный байзлайн:\n",
        "* Точность DecisionTreeClassifier: 0.8819\n",
        "* Среднеквадратичная ошибка DecisionTreeRegressor: 604.377\n",
        "\n",
        "***Итог:*** улучшенный бейзлайн демонстрирует значительный прирост эффективности как для задачи классификации, так и для задачи регрессии."
      ],
      "metadata": {
        "id": "ce_ntjYKbfsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Имплементация алгоритма"
      ],
      "metadata": {
        "id": "GKP6u-sycARY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Decision_Tree_Classifier:\n",
        "    def __init__(self,\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "\n",
        "    def _gini(self, y):\n",
        "        m = len(y)\n",
        "        if m == 0:\n",
        "            return 0\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        p = counts / m\n",
        "        return 1 - np.sum(p * p)\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_gini = 1e10\n",
        "        best_feat = None\n",
        "        best_thr = None\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_idx = X[:, feature].argsort()\n",
        "            X_f = X[sorted_idx, feature]\n",
        "            y_f = y[sorted_idx]\n",
        "\n",
        "            unique_vals = np.unique(X_f)\n",
        "            if len(unique_vals) == 1:\n",
        "                continue\n",
        "\n",
        "\n",
        "            left_counts = {}\n",
        "            right_counts = dict(zip(*np.unique(y_f, return_counts=True)))\n",
        "            left_n = 0\n",
        "            right_n = len(y_f)\n",
        "\n",
        "            for i in range(1, m):\n",
        "                cls = y_f[i - 1]\n",
        "\n",
        "\n",
        "                left_counts[cls] = left_counts.get(cls, 0) + 1\n",
        "                right_counts[cls] -= 1\n",
        "                left_n += 1\n",
        "                right_n -= 1\n",
        "\n",
        "                if X_f[i] == X_f[i - 1]:\n",
        "                    continue\n",
        "                if left_n < self.min_samples_leaf or right_n < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "\n",
        "                left_gini = 1.0\n",
        "                if left_n > 0:\n",
        "                    p = np.fromiter(left_counts.values(), dtype=float) / left_n\n",
        "                    left_gini = 1 - np.sum(p * p)\n",
        "\n",
        "                right_gini = 1.0\n",
        "                if right_n > 0:\n",
        "                    p = np.fromiter(right_counts.values(), dtype=float) / right_n\n",
        "                    right_gini = 1 - np.sum(p * p)\n",
        "\n",
        "                gini = (left_n * left_gini + right_n * right_gini) / m\n",
        "\n",
        "                if gini < best_gini:\n",
        "                    best_gini = gini\n",
        "                    best_feat = feature\n",
        "                    best_thr = (X_f[i] + X_f[i - 1]) / 2\n",
        "\n",
        "        return best_feat, best_thr\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        num_samples = len(y)\n",
        "        num_labels = len(np.unique(y))\n",
        "\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
        "           num_labels == 1 or \\\n",
        "           num_samples < self.min_samples_split:\n",
        "            values, counts = np.unique(y, return_counts=True)\n",
        "            return {\"leaf\": True, \"class\": values[np.argmax(counts)]}\n",
        "\n",
        "        feat, thr = self._best_split(X, y)\n",
        "        if feat is None:\n",
        "            values, counts = np.unique(y, return_counts=True)\n",
        "            return {\"leaf\": True, \"class\": values[np.argmax(counts)]}\n",
        "\n",
        "        left_idx = X[:, feat] <= thr\n",
        "        right_idx = X[:, feat] > thr\n",
        "\n",
        "        return {\n",
        "            \"leaf\": False,\n",
        "            \"feature\": feat,\n",
        "            \"threshold\": thr,\n",
        "            \"left\": self._build_tree(X[left_idx], y[left_idx], depth + 1),\n",
        "            \"right\": self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = np.array(X), np.array(y)\n",
        "        self.tree = self._build_tree(X, y)\n",
        "        return self\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        while not node[\"leaf\"]:\n",
        "            if x[node[\"feature\"]] <= node[\"threshold\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node[\"class\"]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.tree) for x in X])\n"
      ],
      "metadata": {
        "id": "EIuEH_7Da6te"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_Decision_Tree_Regressor:\n",
        "    def __init__(self,\n",
        "                 max_depth=None,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.min_samples_leaf = min_samples_leaf\n",
        "        self.tree = None\n",
        "\n",
        "\n",
        "    def _variance(self, y):\n",
        "        return np.var(y) if len(y) > 0 else 0\n",
        "\n",
        "    def _best_split(self, X, y):\n",
        "        m, n = X.shape\n",
        "        if m < self.min_samples_split:\n",
        "            return None, None\n",
        "\n",
        "        best_feat, best_thr = None, None\n",
        "        best_var = 1e18\n",
        "\n",
        "        total_sum = y.sum()\n",
        "        total_sq_sum = np.dot(y, y)\n",
        "\n",
        "        for feature in range(n):\n",
        "            sorted_idx = np.argsort(X[:, feature])\n",
        "            X_f = X[sorted_idx, feature]\n",
        "            y_f = y[sorted_idx]\n",
        "\n",
        "            left_sum = 0.0\n",
        "            left_sq_sum = 0.0\n",
        "            left_n = 0\n",
        "\n",
        "\n",
        "            right_sum = total_sum\n",
        "            right_sq_sum = total_sq_sum\n",
        "            right_n = m\n",
        "\n",
        "            for i in range(1, m):\n",
        "                yi = y_f[i - 1]\n",
        "\n",
        "\n",
        "                left_sum += yi\n",
        "                left_sq_sum += yi * yi\n",
        "                left_n += 1\n",
        "\n",
        "                right_sum -= yi\n",
        "                right_sq_sum -= yi * yi\n",
        "                right_n -= 1\n",
        "\n",
        "\n",
        "                if X_f[i] == X_f[i - 1]:\n",
        "                    continue\n",
        "\n",
        "                if left_n < self.min_samples_leaf or right_n < self.min_samples_leaf:\n",
        "                    continue\n",
        "\n",
        "\n",
        "                left_var = left_sq_sum / left_n - (left_sum / left_n)**2\n",
        "\n",
        "                right_var = right_sq_sum / right_n - (right_sum / right_n)**2\n",
        "\n",
        "\n",
        "                weighted_var = left_n * left_var + right_n * right_var\n",
        "\n",
        "                if weighted_var < best_var:\n",
        "                    best_var = weighted_var\n",
        "                    best_feat = feature\n",
        "                    best_thr = (X_f[i] + X_f[i - 1]) / 2\n",
        "\n",
        "        return best_feat, best_thr\n",
        "\n",
        "    def _build_tree(self, X, y, depth=0):\n",
        "        m = len(y)\n",
        "\n",
        "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
        "           m < self.min_samples_split or \\\n",
        "           np.var(y) < 1e-10:\n",
        "            return {\"leaf\": True, \"value\": np.mean(y)}\n",
        "\n",
        "        feat, thr = self._best_split(X, y)\n",
        "\n",
        "        if feat is None:\n",
        "            return {\"leaf\": True, \"value\": np.mean(y)}\n",
        "\n",
        "        left_idx = X[:, feat] <= thr\n",
        "        right_idx = ~left_idx\n",
        "\n",
        "        return {\n",
        "            \"leaf\": False,\n",
        "            \"feature\": feat,\n",
        "            \"threshold\": thr,\n",
        "            \"left\": self._build_tree(X[left_idx], y[left_idx], depth + 1),\n",
        "            \"right\": self._build_tree(X[right_idx], y[right_idx], depth + 1)\n",
        "        }\n",
        "\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X, y = np.array(X), np.array(y, dtype=float)\n",
        "        self.tree = self._build_tree(X, y)\n",
        "        return self\n",
        "\n",
        "    def _predict_one(self, x, node):\n",
        "        while not node[\"leaf\"]:\n",
        "            if x[node[\"feature\"]] <= node[\"threshold\"]:\n",
        "                node = node[\"left\"]\n",
        "            else:\n",
        "                node = node[\"right\"]\n",
        "        return node[\"value\"]\n",
        "\n",
        "    def predict(self, X):\n",
        "        X = np.array(X)\n",
        "        return np.array([self._predict_one(x, self.tree) for x in X])\n"
      ],
      "metadata": {
        "id": "Zim_6eEnd-CW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_classification(df_class)\n",
        "\n",
        "model = My_Decision_Tree_Classifier()\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "accuracy_class = accuracy_score(y_test, predictions)\n",
        "print(f\"Точность My_Decision_Tree_Classifier: {accuracy_class:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHjQXDDvdcO5",
        "outputId": "37d51c6b-b447-492f-c6aa-67bea23ed214"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Точность My_Decision_Tree_Classifier: 0.8257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = simple_regression(df_reg)\n",
        "\n",
        "model = My_Decision_Tree_Regressor()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "mse_reg = mean_squared_error(y_test, predictions)\n",
        "print(f\"Среднеквадратичная ошибка  My_Decision_Tree_Regressor: {mse_reg:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Wu8t1vdjRJ",
        "outputId": "4259433e-fe14-4aab-d675-564cc9185826"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднеквадратичная ошибка  My_Decision_Tree_Regressor: 961.1001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_classification(df_class)"
      ],
      "metadata": {
        "id": "DytBclQieS2l"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_params(type_task, my_model,\n",
        "                  X_train, X_test, y_train, y_test,\n",
        "                  depths=(3, 5, 10),\n",
        "                  splits=(2, 4, 6, 10),\n",
        "                  leaves=(1, 2, 4)):\n",
        "\n",
        "    best_score = -1e18 if type_task == 'clf' else 1e18\n",
        "    best_params = None\n",
        "\n",
        "    for depth in depths:\n",
        "        for split in splits:\n",
        "            for leaf in leaves:\n",
        "\n",
        "                model = my_model(\n",
        "                    max_depth=depth,\n",
        "                    min_samples_split=split,\n",
        "                    min_samples_leaf=leaf\n",
        "                )\n",
        "\n",
        "                model.fit(X_train, y_train)\n",
        "                preds = model.predict(X_test)\n",
        "\n",
        "                if type_task == 'clf':\n",
        "                    score = accuracy_score(y_test, preds)\n",
        "                    if score > best_score:\n",
        "                        best_score = score\n",
        "                        best_params = (depth, split, leaf)\n",
        "\n",
        "                else:\n",
        "                    score = mean_squared_error(y_test, preds)\n",
        "                    if score < best_score:\n",
        "                        best_score = score\n",
        "                        best_params = (depth, split, leaf)\n",
        "\n",
        "    return best_score, best_params\n"
      ],
      "metadata": {
        "id": "1XtyN8AofBru"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc, best_params = search_params('clf',My_Decision_Tree_Classifier,X_train,X_test,y_train,y_test)\n",
        "print(f\"Лучшая точность My_Decision_Tree_Classifier: {acc:.4f}\")\n",
        "print(f\"Best params: max_depth={best_params[0]}, min_sample_split={best_params[1]}, min_sample_leaf={best_params[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-Jei_jqiFCe",
        "outputId": "03861317-7b2d-426d-8fea-6f52a46a6d54"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая точность My_Decision_Tree_Classifier: 0.8807\n",
            "Best params: max_depth=10, min_sample_split=2, min_sample_leaf=4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = upgraded_regression(df_reg)"
      ],
      "metadata": {
        "id": "W6tSA1K2eyAo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse, best_params = search_params('reg',My_Decision_Tree_Regressor,X_train,X_test,y_train,y_test)\n",
        "print(f\"Лучшая среднеквадратичная ошибка My_Decision_Tree_Regressor: {mse:.4f}\")\n",
        "print(f\"Best params: max_depth={best_params[0]}, min_sample_split={best_params[1]}, min_sample_leaf={best_params[2]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTydy-Ysgb-2",
        "outputId": "06e7a6a4-7582-4b06-e2c4-228a35a5c42d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшая среднеквадратичная ошибка My_Decision_Tree_Regressor: 635.0551\n",
            "Best params: max_depth=5, min_sample_split=2, min_sample_leaf=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Стандартный бейзлайн:\n",
        "\n",
        "Библиотечная реализация:\n",
        "* Точность DecisionTreeClassifier: 0.8286\n",
        "* Среднеквадратичная ошибка DecisionTreeRegressor: 890.9472\n",
        "\n",
        "Имплементация алгоритма:\n",
        "* Точность My_Decision_Tree_Classifier: 0.8257\n",
        "* Среднеквадратичная ошибка My_Decision_Tree_Regressor: 961.1001\n",
        "\n",
        "Улучшенный байзлайн:\n",
        "\n",
        "Библиотечная реализация:\n",
        "* Точность DecisionTreeClassifier: 0.8819\n",
        "* Среднеквадратичная ошибка DecisionTreeRegressor: 604.377\n",
        "\n",
        "Имплементация алгоритма:\n",
        "* точность My_Decision_Tree_Classifier: 0.8807\n",
        "* среднеквадратичная ошибка My_Decision_Tree_Regressor: 635.0551\n",
        "\n",
        "\n",
        "***Итог:*** В рамках лабораторной работы были построены и проанализированы стандартный и улучшенный бейзлайны для моделей на основе деревьев решений, как в библиотечной реализации, так и в собственной имплементации.\n",
        "\n",
        "Улучшение бейзлайна положительно сказалось на качествах как классификаторов, так и регрессоров во всех вариантах реализации.\n",
        "Библиотечные модели показали более высокие результаты в обоих бейзлайнах, что ожидаемо благодаря оптимизированным внутренним механизмам и проверенным стратегиям разбиения.\n",
        "Собственная реализация, хотя и изначально уступала библиотечной, также адекватно отреагировала на улучшение бейзлайна, сократив отставание.\n",
        "Эти результаты подтверждают корректность реализованных алгоритмов и демонстрируют влияние предварительной обработки данных или улучшения гиперпараметров на итоговое качество."
      ],
      "metadata": {
        "id": "f52JclL-miMS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bkPtF0vmGZh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}